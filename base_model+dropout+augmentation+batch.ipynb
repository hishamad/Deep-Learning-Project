{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kyqOgTWzCTUX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "import pickle\n",
        "from keras.regularizers import l2\n",
        "from  scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y67Ec5FICTUd"
      },
      "source": [
        "#### Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYNU45pfCTUf"
      },
      "source": [
        "Load dataset + One-hot encoding + Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o8BGn2ZOCTUg"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "    # One-hot encoding\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "    # Normalize to [0,1]\n",
        "    trainX = trainX.astype('float32') / 255.0\n",
        "    testX = testX.astype('float32') / 255.0\n",
        "\n",
        "    return trainX, trainY, testX, testY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eHdUCx4CTUg"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZUdh8aqCTUh"
      },
      "source": [
        "Imortant functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BGpONL8FCTUh"
      },
      "outputs": [],
      "source": [
        "def train(model, trainX, trainY, testX, testY):\n",
        "\tgenerator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "\ttrain_data = generator.flow(trainX, trainY, batch_size=64)\n",
        "\n",
        "\tresults = model.fit(train_data, epochs=400, validation_data=(testX, testY), verbose=0)\n",
        "\n",
        "\treturn results\n",
        "\n",
        "def evaluate(model, testX, testY):\n",
        "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\n",
        "    print(f\"The model achieved a final accuracy of {acc*100:.2f}%\")\n",
        "\n",
        "def plot_results(history):\n",
        "\tplt.title('Cross Entropy Loss')\n",
        "\tplt.plot(history['loss'], color='blue', label='Training loss')\n",
        "\tplt.plot(history['val_loss'], color='orange', label='Validation/test loss')\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "\n",
        "\tplt.title('Classification Accuracy')\n",
        "\tplt.plot(history['accuracy'], color='blue', label='Training accuracy')\n",
        "\tplt.plot(history['val_accuracy'], color='orange', label='Validation/test accuracy')\n",
        "\tplt.legend()\n",
        "\tplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ls19xeC0CTUi"
      },
      "outputs": [],
      "source": [
        "def save_model(filename, model):\n",
        "    filename = 'content/models/' + filename\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "def save_history(filename, history):\n",
        "    filename = 'content/history/' + filename\n",
        "    pickle.dump(history, open(filename, 'wb'))\n",
        "\n",
        "def load_model(filename):\n",
        "    filename = 'content/models/' + filename\n",
        "    model = pickle.load(open(filename, 'rb'))\n",
        "    return model\n",
        "\n",
        "def load_history(filename):\n",
        "    filename = 'content/history/' + filename\n",
        "    history = pickle.load(open(filename, 'rb'))\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXqNA_VcCTUj"
      },
      "source": [
        "Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C9xaw4BBCTUj"
      },
      "outputs": [],
      "source": [
        "def dropout_model():\n",
        "    # Create architecture\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Optimization method\n",
        "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\n",
        "    # Compile model and choose loss type\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_FZ9SNHCTUj",
        "outputId": "202df399-acf4-4056-dfa3-ff8c623e6019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "trainX, trainY, testX, testY = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aSe_cO4CTUk"
      },
      "outputs": [],
      "source": [
        "model = dropout_model()\n",
        "results = train(model, trainX, trainY, testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNdQN-nnCTUk"
      },
      "outputs": [],
      "source": [
        "plot_results(results.history)\n",
        "evaluate(model, testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmsurzVECTUk"
      },
      "outputs": [],
      "source": [
        "save_model('dropout_augment_model', model)\n",
        "save_history('dropout_augment_model', results.history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('content/models/dropout_augment_model')\n",
        "files.download('content/history/dropout_augment_model')"
      ],
      "metadata": {
        "id": "a-l1CJtm0eCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNnZTjmwCTUl",
        "outputId": "0b3a8c95-28a1-425f-b0bd-210d125c0326"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './models/dropout_augment_model'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_344/4078561090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dropout_augment_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhistory_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dropout_augment_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_344/2728459512.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./models/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/dropout_augment_model'"
          ]
        }
      ],
      "source": [
        "test = load_model('dropout_augment_model')\n",
        "history_test = load_history('dropout_augment_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FXGqv_kCTUl"
      },
      "outputs": [],
      "source": [
        "plot_results(history_test)\n",
        "evaluate(test, testX, testY)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}